# EDA_PIB_VS_CALIDAD_DE_VIDA

EDA_proyecto/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Datos originales (NO modificar)
â”‚   â”œâ”€â”€ interim/          # Datos intermedios (limpieza parcial)
â”‚   â””â”€â”€ processed/        # Datos listos para anÃ¡lisis/modelado
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracion.ipynb
â”‚   â”œâ”€â”€ 02_limpieza.ipynb
â”‚   â”œâ”€â”€ 03_analisis.ipynb
â”‚   â””â”€â”€ 04_conclusiones.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/          # GrÃ¡ficas exportadas
â”‚   â””â”€â”€ eda_report.md     # Conclusiones en texto
â”‚
â”œâ”€â”€ environment.yml       # (conda) o requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ main.py               # (opcional) para ejecutar pipeline

Â¿Por quÃ© esta estructura funciona bien?
ğŸ”¹ data/

raw: datos tal como los recibes

processed: datos limpios (los que usas en notebooks)

Evita sobrescribir datos originales â—

ğŸ”¹ notebooks/

Ordenados y numerados â†’ flujo claro

Solo lÃ³gica de exploraciÃ³n

Poco cÃ³digo repetido (eso va en src/)

ğŸ”¹ src/

Funciones reutilizables

Limpieza, features, visualizaciones

Evita notebooks gigantes y desordenados

Ejemplo:

# src/data_processing.py
def clean_columns(df):
    df.columns = df.columns.str.lower().str.replace(" ", "_")
    return df

ğŸ”¹ reports/

Resultados finales

GrÃ¡ficas guardadas con plt.savefig()

Conclusiones claras para entregar

CÃ³mo trabajar desde los notebooks

Dentro de un notebook:

import sys
sys.path.append("../src")

from data_processing import clean_columns


O mejor aÃºn (recomendado):

pip install -e .

.gitignore bÃ¡sico para EDA
__pycache__/
.ipynb_checkpoints/
.env
data/raw/*.csv

README.md mÃ­nimo
# EDA - Calidad de Vida

## Objetivo
Analizar los factores que influyen en la calidad de vida.

## Estructura
- data/: datos
- notebooks/: anÃ¡lisis
- src/: funciones
